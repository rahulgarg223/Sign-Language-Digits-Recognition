# -*- coding: utf-8 -*-
"""Sign Language Digits Recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LXNH3Xs1Zi4QoQxaSt_6DbMMFqea0IkM

# **IML Project: Sign Language Digits Recognition(41)**

### **Project Description**

The dataset contains images of hands representing digits from 0 to 9.The dataset is split into train and test sets. The task is to recognise the number being represented.

*   Professor: Avinash Sharma
*   Mentor: Alli Khadga Jyoth

Team Members:-


*   Yogesh Jajoria(B22ME073)
*   Rahul Garg(B22CH025)


*   Sahil Bhaskar(B22CH052)
*   Ghanshyam(B22PH009)


*   Abhishek Kumar(B22CH001)

### **Mounting Drive**

Connecting to Data
"""

from google.colab import drive                #initiates a process that allows us to mount your Google Drive into the Colab environment
drive.mount('/content/drive')

"""### **Importing Necessary library**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

import os
import cv2

import tensorflow as tf
from tensorflow import keras
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout

"""## **Loading Data**

Checking Class Labels present in the dataset
"""

path_train = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/train'      #path of train directory
print('CLasses present in the Data:- ')
for image_class in os.listdir(path_train):                             # returns a list of items (files and directories) contained within the specified directory
  print(image_class)

"""Visualizing Images of Train set and Test set for number 0"""

path_train_0 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/train/0'   #path of folder

images_train_0 = os.listdir(path_train_0)                             #create list on image files
print("List Of Images: ",images_train_0)
print('Number of Images in Train set 0: ',len(images_train_0))

imgdata_train_0 = []                                                  #Empty list to store image data(RGB format)

for img in images_train_0:
  imgarr_train_0 = cv2.imread(os.path.join(path_train_0,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_train_0)                                          #Display Images
  imgdata_train_0.append(imgarr_train_0)

print("Shape of the Images in Train set 0: ",imgarr_train_0.shape)     #(height, width, channels)

path_test_0 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/test/0'   #path of folder

images_test_0 = os.listdir(path_test_0)                             #create list on image files
print("List Of Images: ",images_test_0)
print('Number of Images in Test set 0: ',len(images_test_0))

imgdata_test_0 = []                                                  #Empty list to store image data(RGB format)

for img in images_test_0:
  imgarr_test_0 = cv2.imread(os.path.join(path_test_0,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_test_0)                                          #Display Images
  imgdata_test_0.append(imgarr_test_0)

print("Shape of the Images in Test set 0: ",imgarr_test_0.shape)     #(height, width, channels)

"""Visualizing Images of Train set and Test set for number 1"""

path_train_1 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/train/1'   #path of folder

images_train_1 = os.listdir(path_train_1)                             #create list on image files
print("List Of Images: ",images_train_1)
print('Number of Images in Train set 1: ',len(images_train_1))

imgdata_train_1 = []                                                  #Empty list to store image data(RGB format)

for img in images_train_1:
  imgarr_train_1 = cv2.imread(os.path.join(path_train_1,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_train_1)                                          #Display Images
  imgdata_train_1.append(imgarr_train_1)

print("Shape of the Images in Train set 1: ",imgarr_train_1.shape)     #(height, width, channels)

path_test_1 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/test/1'   #path of folder

images_test_1 = os.listdir(path_test_1)                             #create list on image files
print("List Of Images: ",images_test_1)
print('Number of Images in Test set 1: ',len(images_test_1))

imgdata_test_1 = []                                                  #Empty list to store image data(RGB format)

for img in images_test_1:
  imgarr_test_1 = cv2.imread(os.path.join(path_test_1,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_test_1)                                          #Display Images
  imgdata_test_1.append(imgarr_test_1)

print("Shape of the Images in Test set 1: ",imgarr_test_1.shape)     #(height, width, channels)

"""Visualizing Images of Train set and Test set for number 2"""

path_train_2 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/train/2'   #path of folder

images_train_2 = os.listdir(path_train_2)                             #create list on image files
print("List Of Images: ",images_train_2)
print('Number of Images in Train set 2: ',len(images_train_2))

imgdata_train_2 = []                                                  #Empty list to store image data(RGB format)

for img in images_train_2:
  imgarr_train_2 = cv2.imread(os.path.join(path_train_2,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_train_2)                                          #Display Images
  imgdata_train_2.append(imgarr_train_2)

print("Shape of the Images in Train set 2: ",imgarr_train_2.shape)     #(height, width, channels)

path_test_2 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/test/2'   #path of folder

images_test_2 = os.listdir(path_test_2)                             #create list on image files
print("List Of Images: ",images_test_2)
print('Number of Images in Test set 2: ',len(images_test_2))

imgdata_test_2 = []                                                  #Empty list to store image data(RGB format)

for img in images_test_2:
  imgarr_test_2 = cv2.imread(os.path.join(path_test_2,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_test_2)                                          #Display Images
  imgdata_test_2.append(imgarr_test_2)

print("Shape of the Images in Test set 2: ",imgarr_test_2.shape)     #(height, width, channels)

"""Visualizing Images of Train set and Test set for number 3"""

path_train_3 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/train/3'   #path of folder

images_train_3 = os.listdir(path_train_3)                             #create list on image files
print("List Of Images: ",images_train_3)
print('Number of Images in Train set 3: ',len(images_train_3))

imgdata_train_3 = []                                                  #Empty list to store image data(RGB format)

for img in images_train_3:
  imgarr_train_3 = cv2.imread(os.path.join(path_train_3,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_train_3)                                          #Display Images
  imgdata_train_3.append(imgarr_train_3)

print("Shape of the Images in Train set 3: ",imgarr_train_3.shape)     #(height, width, channels)

path_test_3 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/test/3'   #path of folder

images_test_3 = os.listdir(path_test_3)                             #create list on image files
print("List Of Images: ",images_test_3)
print('Number of Images in Test set 3: ',len(images_test_3))

imgdata_test_3 = []                                                  #Empty list to store image data(RGB format)

for img in images_test_3:
  imgarr_test_3 = cv2.imread(os.path.join(path_test_3,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_test_3)                                          #Display Images
  imgdata_test_0.append(imgarr_test_3)

print("Shape of the Images in Test set 3: ",imgarr_test_3.shape)     #(height, width, channels)

"""Visualizing Images of Train set and Test set for number 4"""

path_train_4 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/train/4'   #path of folder

images_train_4 = os.listdir(path_train_4)                             #create list on image files
print("List Of Images: ",images_train_4)
print('Number of Images in Train set 4: ',len(images_train_4))

imgdata_train_4 = []                                                  #Empty list to store image data(RGB format)

for img in images_train_4:
  imgarr_train_4 = cv2.imread(os.path.join(path_train_4,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_train_4)                                          #Display Images
  imgdata_train_4.append(imgarr_train_4)

print("Shape of the Images in Train set 4: ",imgarr_train_4.shape)     #(height, width, channels)

path_test_4 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/test/4'   #path of folder

images_test_4 = os.listdir(path_test_4)                             #create list on image files
print("List Of Images: ",images_test_4)
print('Number of Images in Test set 4: ',len(images_test_4))

imgdata_test_4 = []                                                  #Empty list to store image data(RGB format)

for img in images_test_4:
  imgarr_test_4 = cv2.imread(os.path.join(path_test_4,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_test_4)                                          #Display Images
  imgdata_test_0.append(imgarr_test_4)

print("Shape of the Images in Test set 4: ",imgarr_test_4.shape)     #(height, width, channels)

"""Visualizing Images of Train set and Test set for number 5"""

path_train_5 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/train/5'   #path of folder

images_train_5 = os.listdir(path_train_5)                             #create list on image files
print("List Of Images: ",images_train_5)
print('Number of Images in Train set 5: ',len(images_train_5))

imgdata_train_5 = []                                                  #Empty list to store image data(RGB format)

for img in images_train_5:
  imgarr_train_5 = cv2.imread(os.path.join(path_train_5,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_train_5)                                          #Display Images
  imgdata_train_5.append(imgarr_train_5)

print("Shape of the Images in Train set 5: ",imgarr_train_5.shape)     #(height, width, channels)

path_test_5 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/test/5'   #path of folder

images_test_5 = os.listdir(path_test_5)                             #create list on image files
print("List Of Images: ",images_test_5)
print('Number of Images in Test set 5: ',len(images_test_5))

imgdata_test_5 = []                                                  #Empty list to store image data(RGB format)

for img in images_test_5:
  imgarr_test_5 = cv2.imread(os.path.join(path_test_5,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_test_5)                                          #Display Images
  imgdata_test_5.append(imgarr_test_5)

print("Shape of the Images in Test set 5: ",imgarr_test_5.shape)     #(height, width, channels)

"""Visualizing Images of Train set and Test set for number 6"""

path_train_6 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/train/6'   #path of folder

images_train_6 = os.listdir(path_train_6)                             #create list on image files
print("List Of Images: ",images_train_6)
print('Number of Images in Train set 6: ',len(images_train_6))

imgdata_train_6 = []                                                  #Empty list to store image data(RGB format)

for img in images_train_6:
  imgarr_train_6 = cv2.imread(os.path.join(path_train_6,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_train_6)                                          #Display Images
  imgdata_train_6.append(imgarr_train_6)

print("Shape of the Images in Train set 6: ",imgarr_train_6.shape)     #(height, width, channels)

path_test_6 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/test/6'   #path of folder

images_test_6 = os.listdir(path_test_6)                             #create list on image files
print("List Of Images: ",images_test_6)
print('Number of Images in Test set 6: ',len(images_test_6))

imgdata_test_6 = []                                                  #Empty list to store image data(RGB format)

for img in images_test_6:
  imgarr_test_6 = cv2.imread(os.path.join(path_test_6,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_test_6)                                          #Display Images
  imgdata_test_6.append(imgarr_test_6)

print("Shape of the Images in Test set 6: ",imgarr_test_6.shape)     #(height, width, channels)

"""Visualizing Images of Train set and Test set for number 7"""

path_train_7 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/train/7'   #path of folder

images_train_7 = os.listdir(path_train_7)                             #create list on image files
print("List Of Images: ",images_train_7)
print('Number of Images in Train set 7: ',len(images_train_7))

imgdata_train_7 = []                                                  #Empty list to store image data(RGB format)

for img in images_train_7:
  imgarr_train_7 = cv2.imread(os.path.join(path_train_7,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_train_7)                                          #Display Images
  imgdata_train_7.append(imgarr_train_7)

print("Shape of the Images in Train set 7: ",imgarr_train_7.shape)     #(height, width, channels)

path_test_7 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/test/7'   #path of folder

images_test_7 = os.listdir(path_test_7)                             #create list on image files
print("List Of Images: ",images_test_7)
print('Number of Images in Test set 7: ',len(images_test_7))

imgdata_test_7 = []                                                  #Empty list to store image data(RGB format)

for img in images_test_7:
  imgarr_test_7 = cv2.imread(os.path.join(path_test_7,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_test_7)                                          #Display Images
  imgdata_test_7.append(imgarr_test_7)

print("Shape of the Images in Test set 7: ",imgarr_test_7.shape)     #(height, width, channels)

"""Visualizing Images of Train set and Test set for number 8"""

path_train_8 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/train/8'   #path of folder

images_train_8 = os.listdir(path_train_8)                             #create list on image files
print("List Of Images: ",images_train_8)
print('Number of Images in Train set 8: ',len(images_train_8))

imgdata_train_8 = []                                                  #Empty list to store image data(RGB format)

for img in images_train_8:
  imgarr_train_8 = cv2.imread(os.path.join(path_train_8,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_train_8)                                          #Display Images
  imgdata_train_8.append(imgarr_train_8)

print("Shape of the Images in Train set 8: ",imgarr_train_8.shape)     #(height, width, channels)

path_test_8 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/test/8'   #path of folder

images_test_8 = os.listdir(path_test_8)                             #create list on image files
print("List Of Images: ",images_test_8)
print('Number of Images in Test set 8: ',len(images_test_8))

imgdata_test_8 = []                                                  #Empty list to store image data(RGB format)

for img in images_test_8:
  imgarr_test_8 = cv2.imread(os.path.join(path_test_8,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_test_8)                                          #Display Images
  imgdata_test_8.append(imgarr_test_8)

print("Shape of the Images in Test set 8: ",imgarr_test_8.shape)     #(height, width, channels)

"""Visualizing Images of Train set and Test set for number 9"""

path_train_9 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/train/9'   #path of folder

images_train_9 = os.listdir(path_train_9)                             #create list on image files
print("List Of Images: ",images_train_9)
print('Number of Images in Train set 9: ',len(images_train_9))

imgdata_train_9 = []                                                  #Empty list to store image data(RGB format)

for img in images_train_9:
  imgarr_train_9 = cv2.imread(os.path.join(path_train_9,img))         #Read images of particular type at particular path and
  plt.imshow(imgarr_train_9)                                          #Display Images
  imgdata_train_9.append(imgarr_train_9)

print("Shape of the Images in Train set 9: ",imgarr_train_9.shape)     #(height, width, channels)

path_test_9 = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/test/9'   #path of folder

images_test_9 = os.listdir(path_test_9)                                 #create list on image files
print("List Of Images: ",images_test_9)
print('Number of Images in Test set 9: ',len(images_test_9))

imgdata_test_9 = []                                                     #Empty list to store image data(RGB format)

for img in images_test_9:
  imgarr_test_9 = cv2.imread(os.path.join(path_test_9,img))             #Read images of particular type at particular path and
  plt.imshow(imgarr_test_9)                                             #Display Images
  imgdata_test_9.append(imgarr_test_9)

print("Shape of the Images in Test set 9: ",imgarr_test_9.shape)        #(height, width, channels)

"""Load  Training Data"""

# tf.keras.utils.image_dataset_from_directory??

path_train = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/train'           #path of train data directory

img_height = 28                                                                                                           #resize images from (100px, 100px) to (28px, 28px)
img_width = 28
batch_size = 411                                                                                                          #6144/4 (Train data set is very large)
                                                                                                                          #Uses memory efficiently
imgdata_train = tf.keras.utils.image_dataset_from_directory(                                                              #utility function in tensorflow used for loading, labeling and preprocessing of images
    path_train,
    labels = 'inferred',                                                                                                  #infers labels from subdirectory
    label_mode = "int",
    class_names = ['0','1','2','3','4','5','6','7','8','9'],
    color_mode = 'grayscale',                                                                                             #images will be loaded in grayscale mode (single-channel images)
    batch_size = batch_size,
    image_size = (img_height,img_width),
    shuffle = True,
    seed = None
)

"""Converting Train data into numpy array"""

data_iterator = imgdata_train.as_numpy_iterator()                               #Converting TensorFlow data into numpy iterator
batch = data_iterator.next()                                                    #Retrieves the next batch of data from the iterator and store it in batch

# print(type(batch))
print('Number of Arrays in batch Array: ',len(batch))                           #Array contains 2 subarrays
                                                                                #First araay stores image information
                                                                                #Second array stores image labes
print('Shape of Image Data: ',batch[0].shape)
# print(batch[0])
print('Labels of images: \n',batch[1])
print('Number os image labels: ',len(batch[1]))
                                                                                #finding range of pixel intensities present in the images
print('Minimum pixel value: ',batch[0].min())
print('Maximum pixel value: ',batch[0].max())

"""Lets visualize a set of Train dataset"""

class_names = ['0','1','2','3','4','5','6','7','8','9']

plt.figure(figsize=(12,9))
plt.subplots_adjust(wspace=1, hspace=0)                                         #Adjusts the spacing between subplots in the figure
for images, labels in imgdata_train.take(1):                                    #retrieves a batch (take(1)) of images and their corresponding labels
      for i in range(10):                                                       #Loops through the first 10 images and labels in the batch
          print(f'Label: {labels[i].numpy()}, Class Name: {class_names[labels[i].numpy()]}')
          plt.subplot(2, 5, i+1)
          plt.imshow(images[i].numpy().astype('uint8'), cmap='gray')            #Display Images
                                                                                #unit8: convert the pixel values of an image array to an unsigned 8-bit integer format
                                                                                #colormap to gray scale
          plt.title(class_names[labels[i].numpy()])
          plt.colorbar()                                                        #adds colorbar to plots
plt.subplots_adjust
plt.show()

"""Loading Test Data"""

path_test = '/content/drive/MyDrive/IML Project: Sign Language Digits Recognition/Sign Language Dataset/test'            #path of train data directory

img_height = 28                                                                 #resize images from (100px, 100px) to (28px, 28px)
img_width = 28
batch_size = 418

imgdata_test = tf.keras.utils.image_dataset_from_directory(
    path_test,
    labels = 'inferred',                                                        #infers labels from subdirectory
    label_mode = "int",
    class_names = ['0','1','2','3','4','5','6','7','8','9'],
    color_mode = 'grayscale',                                                   #images will be loaded in grayscale mode (single-channel images)
    batch_size = batch_size,
    image_size = (img_height,img_width),
    shuffle = True,
    seed= None
)

"""Converting Test data into Numpy array"""

data_iterator = imgdata_test.as_numpy_iterator()                                #Converting TensorFlow data into numpy iterator
batch = data_iterator.next()                                                    #Retrieves the next batch of data from the iterator and store it in batch

# print(type(batch))
print('Number of Arrays in batch Array: ',len(batch))
print('Shape of Image Data: ',batch[0].shape)
# print(batch[0])
print('Labels of images: \n',batch[1])
print('Number os image labels: ',len(batch[1]))

"""Lets visualize a set of Test dataset"""

class_names = ['0','1','2','3','4','5','6','7','8','9']

plt.figure(figsize=(12,9))
plt.subplots_adjust(wspace=1, hspace=0)                                         #Adjusts the spacing between subplots in the figure
for images, labels in imgdata_test.take(1):                                     #retrieves a batch (take(1)) of images and their corresponding labels
      for i in range(10):                                                       #Loops through the first 10 images and labels in the batch
          print(f'Label: {labels[i].numpy()}, Class Name: {class_names[labels[i].numpy()]}')
          plt.subplot(2, 5, i+1)
          plt.imshow(images[i].numpy().astype('uint8'), cmap='gray')            #Display Images
                                                                                #unit8: convert the pixel values of an image array to an unsigned 8-bit integer format
                                                                                #colormap to gray scale
          plt.title(class_names[labels[i].numpy()])
          plt.colorbar()                                                        #adds colorbar to plots
plt.subplots_adjust
plt.show()

"""## **Data Normalization**

Normalization of Train data
"""

imgdata_normalized_train = imgdata_train.map(lambda x, y: (x/255, y))           #applying a mapping function to the dataset imgdata_train
                                                                                #Scale pixel values between 0 and 1  by dividing the image data by 255
                                                                                #lambda creates a function in which y(labels) remain unchanged

data_iterator = imgdata_normalized_train.as_numpy_iterator()                    #Converting TensorFlow data into numpy iterator
batch = data_iterator.next()                                                    #Retrieves the next batch of data from the iterator and store it in batch

print('Number of Arrays in batch Array: ',len(batch))                           #Array contains 2 subarrays
                                                                                #First araay stores image information
                                                                                #Second array stores image labes
print('Shape of Image Data: ',batch[0].shape)
print('Labels of images: \n',batch[1])
print('Number os image labels: ',len(batch[1]))
                                                                                #finding range of pixel intensities present in the images
print('Minimum pixel value: ',batch[0].min())
print('Maximum pixel value: ',batch[0].max())

"""Visualization of Normalized Train Data"""

class_names = ['0','1','2','3','4','5','6','7','8','9']

plt.figure(figsize=(12,9))
plt.subplots_adjust(wspace=1, hspace=0)                                         #Adjusts the spacing between subplots in the figure
for images, labels in imgdata_normalized_train.take(1):                                    #retrieves a batch (take(1)) of images and their corresponding labels
      for i in range(10):                                                       #Loops through the first 10 images and labels in the batch
          print(f'Label: {labels[i].numpy()}, Class Name: {class_names[labels[i].numpy()]}')
          plt.subplot(2, 5, i+1)
          plt.imshow(images[i].numpy().astype('uint8'), cmap='gray')            #Display Images
                                                                                #unit8: convert the pixel values of an image array to an unsigned 8-bit integer format
                                                                                #colormap to gray scale
          plt.title(class_names[labels[i].numpy()])
          plt.colorbar()                                                        #adds colorbar to plots
plt.subplots_adjust
plt.show()

"""Normalization of Test Data"""

imgdata_normalized_test = imgdata_test.map(lambda x, y: (x/255, y))           #applying a mapping function to the dataset imgdata_test
                                                                                #Scale pixel values between 0 and 1  by dividing the image data by 255
                                                                                #lambda creates a function in which y(labels) remain unchanged

data_iterator = imgdata_normalized_test.as_numpy_iterator()                    #Converting TensorFlow data into numpy iterator
batch = data_iterator.next()                                                    #Retrieves the next batch of data from the iterator and store it in batch

print('Number of Arrays in batch Array: ',len(batch))                           #Array contains 2 subarrays
                                                                                #First araay stores image information
                                                                                #Second array stores image labes
print('Shape of Image Data: ',batch[0].shape)
print('Labels of images: \n',batch[1])
print('Number os image labels: ',len(batch[1]))
                                                                                #finding range of pixel intensities present in the images
print('Minimum pixel value: ',batch[0].min())
print('Maximum pixel value: ',batch[0].max())

"""Visualization of Normalized Test Data"""

class_names = ['0','1','2','3','4','5','6','7','8','9']

plt.figure(figsize=(12,9))
plt.subplots_adjust(wspace=1, hspace=0)                                         #Adjusts the spacing between subplots in the figure
for images, labels in imgdata_normalized_test.take(1):                                    #retrieves a batch (take(1)) of images and their corresponding labels
      for i in range(10):                                                       #Loops through the first 10 images and labels in the batch
          print(f'Label: {labels[i].numpy()}, Class Name: {class_names[labels[i].numpy()]}')
          plt.subplot(2, 5, i+1)
          plt.imshow(images[i].numpy().astype('uint8'), cmap='gray')            #Display Images
                                                                                #unit8: convert the pixel values of an image array to an unsigned 8-bit integer format
                                                                                #colormap to gray scale
          plt.title(class_names[labels[i].numpy()])
          plt.colorbar()                                                        #adds colorbar to plots
plt.subplots_adjust
plt.show()

"""## **Model: PCA and SVM**"""

import tensorflow as tf
import numpy as np
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# we have a TensorFlow dataset, e.g., imgdata_normalized_train
# And now we have to
# Convert TensorFlow dataset to NumPy arrays
data_iterator = imgdata_normalized_train.as_numpy_iterator()
batch = data_iterator.next()
images, labels = batch

num_samples, num_features = images.shape[0], np.prod(images.shape[1:])
images_2d = images.reshape(num_samples, num_features)                      # Reshaping the images to a 2D array
plt.figure(figsize=(12,15))
plt.imshow(images_2d)

from sklearn.decomposition import PCA

                             # Calculating PCA for various numbers of components
max_components = 150         # Maximum number of components to test
explained_variances = []

for n in range(1, max_components + 1):
    pca = PCA(n_components=n)
    pca.fit(images_2d)
    explained_variances.append(np.sum(pca.explained_variance_ratio_))


# Plotting the explained variance ratio vs. number of components
plt.figure(figsize=(10, 6))
plt.plot(range(1, max_components + 1), explained_variances, marker='o')
plt.xlabel('Number of Components')
plt.ylabel('Explained Variance Ratio')
plt.title('Explained Variance Ratio vs. Number of Components')
plt.grid(True)
plt.show()

# Standardize the data
scaler = StandardScaler()
images_standardized = scaler.fit_transform(images_2d)

# Applying PCA
num_components = 140                    # Adjust the number of components as needed
pca = PCA(n_components=num_components)
images_pca = pca.fit_transform(images_standardized)

                                        # Now 'images_pca' contains the principal components of your data

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score


# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(images_pca, labels, test_size=0.2, random_state=42)



svm_classifier = SVC()            # Initializing a Support Vector Machine (SVM) classifier

hist=svm_classifier.fit(X_train, y_train)        # Training the classifier on the training data

predictions = svm_classifier.predict(X_test)      # Making predictions on the test data

accuracy = accuracy_score(y_test, predictions)    # accuracy of the classifier
print(f"Accuracy: {accuracy * 100:.2f}%")

import tensorflow as tf
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score


# Convert the TensorFlow dataset to NumPy arrays
test_iterator = imgdata_normalized_test.as_numpy_iterator()
test_batch = test_iterator.next()
test_images, test_labels = test_batch

# Reshape the images
num_samples_test, num_features_test = test_images.shape[0], np.prod(test_images.shape[1:])
test_images_2d = test_images.reshape(num_samples_test, num_features_test)

# Standardize the test data using the same scaler used for training
test_images_standardized = scaler.transform(test_images_2d)  # Assuming 'scaler' is your trained StandardScaler

# Apply PCA to reduce dimensionality
test_images_pca = pca.transform(test_images_standardized)

# Make predictions using the SVM classifier
predictions_svm = svm_classifier.predict(test_images_pca)

# Evaluate the accuracy on the test data (if ground truth labels are available)
accuracy = accuracy_score(test_labels, predictions_svm)
print(f"Accuracy on test data: {accuracy * 100:.2f}%")

test_labels       #Original labels

predictions_svm      #predicted labels

"""## **Train Test Validation Split for CNN**

*   We have total 1644 images in training data so divided them into 4 batches(each batch contain 411 images)
*   Test data contains 418 images so used all data in single batch
"""

print('Number of Batches in Train Datasat: ',len(imgdata_normalized_train))
print('Number of Batches in Test Datasat: ',len(imgdata_normalized_test))

"""Lets do Train-Validation split on train data in Ratio 75:25"""

train_size = int(len(imgdata_normalized_train)*0.75)                            #75% of Trained Normalized data will be used as train data
print('Number of Batches in Train Datasat: ',train_size)
val_size = int(len(imgdata_normalized_train)*0.25)                              #25% of Trained Normalized data will be used as test data
print('Number of Batches in Valodation Datasat: ',val_size)
test_size = int(len(imgdata_normalized_test)*1)
print('Number of Batches in Test Datasat: ',test_size)

train_size+val_size+test_size

train = imgdata_normalized_train.take(train_size)
print('Number of Batches in Train Datasat: ',len(train))
val = imgdata_normalized_train.skip(train_size).take(val_size)
print('Number of Batches in Validation Datasat: ',len(val))
test = imgdata_normalized_test.take(test_size)
print('Number of Batches in Test Datasat: ',len(test))

"""## **CNN Model**"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout

model = Sequential()                                                            #initialize an empty Sequential model

"""Model Architecture"""

# Convolutional layers are designed to extract hierarchical features from the input images while reducing spatial dimensions
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))       #adds a convolutional layer with 32 filters each filter having a size of 3x3
model.add(MaxPooling2D((2, 2)))                        #adds a max-pooling layer with a pool size of 2x2 reducing the spatial dimensions of the data

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

model.add(Flatten())                                                            #flattens the output into a 1D array

model.add(Dense(128, activation='relu'))                                        # fully connected layer with 128 neurons and uses the ReLU activation function
model.add(Dense(10, activation='softmax'))             #final fully connected layer consists of 10 neurons, representing the output classes (digits 0 to 9)

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
#loss function measures how well model performs by calculating the cross-entropy between the predicted probability distribution and the true probability distribution of the classes

model.summary()

"""Training data on CNN Model"""

logdir = 'logs'                                                                 #specifies the directory where the TensorBoard logs will be stored
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)           #callback will store data like loss, metrics, and model graphs in the specified directory
# print(tensorboard_callback)
hist = model.fit(imgdata_normalized_train, epochs=100, validation_data=val, callbacks=[tensorboard_callback])

"""Visualize the training and validation loss over epochs during the model training process"""

fig = plt.figure()
plt.plot(hist.history['loss'], color = 'teal', label = 'loss')                  #plt training loss values logged during the training process
plt.plot(hist.history['val_loss'], color = 'orange', label = 'val_loss')        #plt training validation loss values logged during the training process
fig.suptitle('Loss', fontsize = 17)
plt.legend(loc = 'upper right')
plt.show()

"""Visualize the training and validation accuracy over epochs during the model training process"""

fig = plt.figure()
plt.plot(hist.history['accuracy'], color = 'teal', label = 'accuracy')                #plt training accuracy values logged during the training process
plt.plot(hist.history['val_accuracy'], color = 'orange', label = 'val_accuracy')      #plt training validation accuracy values logged during the training process
fig.suptitle('Accuracy', fontsize = 17)
plt.legend(loc = 'upper left')
plt.show()

"""## **Model Evaluation and Prediction**"""

probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])

def plot_image(i, predictions_array, true_label, img):
  true_label, img = true_label[i], img[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label]),
                                color=color)

def plot_value_array(i, predictions_array, true_label):
  true_label = true_label[i]
  plt.grid(False)
  plt.xticks(range(10))
  plt.yticks([])
  thisplot = plt.bar(range(10), predictions_array, color="#777777")
  plt.ylim([0, 1])
  predicted_label = np.argmax(predictions_array)

  thisplot[predicted_label].set_color('red')
  thisplot[true_label].set_color('blue')

predictions = probability_model.predict(imgdata_normalized_test)

#Prediction is an array of 10 numbers. Each element represents the confidance that the image corresponds to the each of the 10 different classes
predictions[0]

np.argmax(predictions[0])

for images, labels in imgdata_normalized_test.take(1):
  i = 0
  plt.figure(figsize=(6,3))
  plt.subplot(1,2,1)
  plot_image(i, predictions[i], labels, images)
  plt.subplot(1,2,2)
  plot_value_array(i, predictions[i],  labels)
  plt.show()